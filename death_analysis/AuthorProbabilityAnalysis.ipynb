{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, os,sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "from dbfuncs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_dir = \"/home/srivbane/shared/caringbridge/data/projects/qual-health-journeys/identify_candidate_sites\"\n",
    "valid_classification_sites_filename = os.path.join(working_dir, \"valid_classification_sites.txt\")\n",
    "valid_sites_filtered_filename = os.path.join(working_dir, \"valid_classification_sites_filtered.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58363\n"
     ]
    }
   ],
   "source": [
    "file_name = valid_classification_sites_filename #58000\n",
    "#file_name = valid_sites_filtered_filename #5000\n",
    "\n",
    "if os.path.exists(file_name):\n",
    "    with open(file_name, 'r') as infile:\n",
    "        valid_sites = [int(line.strip()) for line in infile.readlines() if line.strip() != \"\"]\n",
    "else:\n",
    "    valid_sites = []\n",
    "    \n",
    "print(len(valid_sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc = \"/panfs/roc/groups/3/srivbane/shared/caringbridge/data/projects/qual-health-journeys/death_analysis/\"\n",
    "df = pd.read_csv(loc+\"cleaned_probability.csv\")\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def author_probability(site_id):\n",
    "    journal_oids = get_site_journal_oid(site_id)\n",
    "    \n",
    "    total = 0\n",
    "    count = 0\n",
    "    \n",
    "    ds = df.loc[df['site_id'] == site_id] \n",
    "    \n",
    "    for x in journal_oids:\n",
    "        a = ds.loc[ds['journal_oid'] == x] \n",
    "        \n",
    "        if len(a) != 0:\n",
    "            if a['is_patient'].iloc[0]:\n",
    "                total += 1\n",
    "                count += 1\n",
    "            else:\n",
    "                count += 1\n",
    "                \n",
    "    if len(a) == 0 or a['is_patient'].iloc[0]:\n",
    "        last_patient = 1\n",
    "    else:\n",
    "        last_patient = 0\n",
    "    \n",
    "    return [site_id,total,count,last_patient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58363/58363 [52:50<00:00, 18.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for x in tqdm(range(len(valid_sites))):\n",
    "    \n",
    "    results.append(author_probability(valid_sites[x]))\n",
    "\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = \"58363_probability.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerow([\"site_id\",\"patient_authored\",\"total_count\",\"patient_authored_percentage\",\"last_patient_authored\"])\n",
    "    for val in results:\n",
    "        if len(val) != 5:\n",
    "            if val[2] == 0:\n",
    "                percentage = 0\n",
    "            else:\n",
    "                percentage = val[1]/val[2]*100\n",
    "            val.insert(3,percentage)\n",
    "        writer.writerow(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1097560, 0, 30, 0.0, 0], [1097940, 8, 8, 100.0, 1], [1097953, 0, 22, 0.0, 0], [1099282, 1, 5, 20.0, 0], [1099418, 0, 15, 0.0, 0], [1099548, 2, 9, 22.22222222222222, 0], [1099652, 3, 15, 20.0, 0], [1099768, 1, 11, 9.090909090909092, 0], [1101066, 2, 14, 14.285714285714285, 0], [1101720, 1, 17, 5.88235294117647, 1]]\n"
     ]
    }
   ],
   "source": [
    "print (results[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
