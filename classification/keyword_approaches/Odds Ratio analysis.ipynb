{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Odds Ratio analysis\n",
    "\n",
    "Goal: Compute the frequency-based odds ratio for each term.\n",
    "\n",
    "Based on the Forum77 work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../annotation_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from responsibility import *\n",
    "from phase import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.monitor_interval = 0\n",
    "from nltk import word_tokenize, bigrams, ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import re\n",
    "import time\n",
    "from utils import *\n",
    "from db import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import matplotlib\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = \"/home/srivbane/shared/caringbridge/data/projects/qual-health-journeys/classification/baseline_set_cover\"\n",
    "assert os.path.exists(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1895"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_subset = high_irr_responsibility_labels\n",
    "annotated_df_resp = get_annotated_responsibility_df_fixed(conflict_score_cost=0.1, resp_subset=resp_subset)\n",
    "len(annotated_df_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>conflict_status</th>\n",
       "      <th>journal_oid</th>\n",
       "      <th>responsibilities</th>\n",
       "      <th>site_id</th>\n",
       "      <th>journal_text</th>\n",
       "      <th>is_annotated</th>\n",
       "      <th>coordinating_support_score</th>\n",
       "      <th>sharing_medical_info_score</th>\n",
       "      <th>compliance_score</th>\n",
       "      <th>financial_management_score</th>\n",
       "      <th>giving_back_score</th>\n",
       "      <th>behavior_changes_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SINGLE USER</td>\n",
       "      <td>51be14196ca0041935009526</td>\n",
       "      <td>[]</td>\n",
       "      <td>106710</td>\n",
       "      <td>NEWLINE I will try to update this weekly if I...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index conflict_status               journal_oid responsibilities  site_id  \\\n",
       "0      1     SINGLE USER  51be14196ca0041935009526               []   106710   \n",
       "\n",
       "                                        journal_text  is_annotated  \\\n",
       "0   NEWLINE I will try to update this weekly if I...          True   \n",
       "\n",
       "   coordinating_support_score  sharing_medical_info_score  compliance_score  \\\n",
       "0                         0.0                         0.0               0.0   \n",
       "\n",
       "   financial_management_score  giving_back_score  behavior_changes_score  \n",
       "0                         0.0                0.0                     0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_df_resp.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['communicating', 'info_filtering', 'clinical_decisions', 'preparation', 'symptom_management', 'coordinating_support', 'sharing_medical_info', 'compliance', 'managing_transitions', 'financial_management', 'continued_monitoring', 'giving_back', 'behavior_changes']\n"
     ]
    }
   ],
   "source": [
    "print(responsibility_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coordinating_support', 'sharing_medical_info', 'compliance', 'financial_management', 'giving_back', 'behavior_changes']\n"
     ]
    }
   ],
   "source": [
    "print(resp_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir_phase = '/home/srivbane/shared/caringbridge/data/projects/qual-health-journeys/classification/phases/vw'\n",
    "assert os.path.exists(working_dir_phase)\n",
    "phases_df_filepath = os.path.join(working_dir_phase, 'full_df.pkl')\n",
    "phases_df = pd.read_pickle(phases_df_filepath)\n",
    "annotated_df_phase = phases_df[phases_df.is_annotated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conflict_status</th>\n",
       "      <th>created_at</th>\n",
       "      <th>cured_score</th>\n",
       "      <th>end_of_life_score</th>\n",
       "      <th>is_annotated</th>\n",
       "      <th>journal_index</th>\n",
       "      <th>journal_oid</th>\n",
       "      <th>journal_text</th>\n",
       "      <th>phases</th>\n",
       "      <th>pretreatment_score</th>\n",
       "      <th>site_id</th>\n",
       "      <th>treatment_score</th>\n",
       "      <th>seconds_since_previous_journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SINGLE USER</td>\n",
       "      <td>1231857720000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>51be13d66ca004413400c0c5</td>\n",
       "      <td>NEWLINE I went to see my oncologist, Dr. Abub...</td>\n",
       "      <td>[treatment]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  conflict_status     created_at  cured_score  end_of_life_score  \\\n",
       "0     SINGLE USER  1231857720000          0.0                0.0   \n",
       "\n",
       "   is_annotated  journal_index               journal_oid  \\\n",
       "0          True              0  51be13d66ca004413400c0c5   \n",
       "\n",
       "                                        journal_text       phases  \\\n",
       "0   NEWLINE I went to see my oncologist, Dr. Abub...  [treatment]   \n",
       "\n",
       "   pretreatment_score  site_id  treatment_score  \\\n",
       "0                 0.0   105628              1.0   \n",
       "\n",
       "   seconds_since_previous_journal  \n",
       "0                            -1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_df_phase.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158109"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pretreatment', 'treatment', 'end_of_life', 'cured']\n"
     ]
    }
   ],
   "source": [
    "print(phase_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def commonize_token(token):    \n",
    "    token = token.strip()\n",
    "    token = re.sub('\\d', '0', token)\n",
    "    token = re.sub('[^\\w\\$\\.\\']', '|', token)\n",
    "    token = token.lower()\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_grams(text, n_values=[1], remove_stop = True):\n",
    "    tokens = word_tokenize(text)\n",
    "    if remove_stop:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [tok for tok in tokens if tok not in stop_words]\n",
    "    tokens = [commonize_token(tok) for tok in tokens]\n",
    "    grams = []\n",
    "    for n in n_values:\n",
    "        grams += [' '.join(i) for i in ngrams(tokens, n)]\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df_phase = annotated_df_phase.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df_phase['tokens'] = annotated_df_phase.journal_text.map(lambda text: get_grams(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df_resp['tokens'] = annotated_df_resp.journal_text.map(lambda text: get_grams(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [newline, i, went, see, oncologist, |, dr., ab...\n",
       "1    [newline, my, friends, |, thank, much, continu...\n",
       "2    [newline, had, echo|cardiogram, done, schedule...\n",
       "3    [newline, yesterday, i, signed, take, voice, l...\n",
       "4    [newline, i, received, results, echo|cardiogra...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_df_phase['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conflict_status</th>\n",
       "      <th>created_at</th>\n",
       "      <th>cured_score</th>\n",
       "      <th>end_of_life_score</th>\n",
       "      <th>is_annotated</th>\n",
       "      <th>journal_index</th>\n",
       "      <th>journal_oid</th>\n",
       "      <th>journal_text</th>\n",
       "      <th>phases</th>\n",
       "      <th>pretreatment_score</th>\n",
       "      <th>site_id</th>\n",
       "      <th>treatment_score</th>\n",
       "      <th>seconds_since_previous_journal</th>\n",
       "      <th>tokens</th>\n",
       "      <th>is_pretreatment</th>\n",
       "      <th>is_treatment</th>\n",
       "      <th>is_end_of_life</th>\n",
       "      <th>is_cured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SINGLE USER</td>\n",
       "      <td>1231857720000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>51be13d66ca004413400c0c5</td>\n",
       "      <td>NEWLINE I went to see my oncologist, Dr. Abub...</td>\n",
       "      <td>[treatment]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[newline, i, went, see, oncologist, |, dr., ab...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  conflict_status     created_at  cured_score  end_of_life_score  \\\n",
       "0     SINGLE USER  1231857720000          0.0                0.0   \n",
       "\n",
       "   is_annotated  journal_index               journal_oid  \\\n",
       "0          True              0  51be13d66ca004413400c0c5   \n",
       "\n",
       "                                        journal_text       phases  \\\n",
       "0   NEWLINE I went to see my oncologist, Dr. Abub...  [treatment]   \n",
       "\n",
       "   pretreatment_score  site_id  treatment_score  \\\n",
       "0                 0.0   105628              1.0   \n",
       "\n",
       "   seconds_since_previous_journal  \\\n",
       "0                            -1.0   \n",
       "\n",
       "                                              tokens  is_pretreatment  \\\n",
       "0  [newline, i, went, see, oncologist, |, dr., ab...            False   \n",
       "\n",
       "   is_treatment  is_end_of_life  is_cured  \n",
       "0          True           False     False  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for phase_label in phase_labels:\n",
    "    annotated_df_phase[\"is_\" + phase_label] = annotated_df_phase[phase_label + \"_score\"] >= 0.5\n",
    "annotated_df_phase.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for resp_label in resp_subset:\n",
    "    annotated_df_resp[\"is_\" + resp_label] = annotated_df_resp[resp_label + \"_score\"] >= 0.5\n",
    "annotated_df_resp.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beginning of primary implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_word_counts(df, labels):\n",
    "    label_word_counts = {label: defaultdict(int) for label in labels}\n",
    "    label_cols = [\"is_\" + label for label in labels]\n",
    "    # for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    for _, row in df.iterrows():\n",
    "        update_label_counts(row, labels, label_cols, label_word_counts)\n",
    "    return label_word_counts\n",
    "\n",
    "def update_label_counts(entry, labels, label_cols, label_word_counts):\n",
    "    label_bools = [entry[label_col] for label_col in label_cols]\n",
    "    tokens = entry.tokens\n",
    "    for token in set(tokens):\n",
    "        for i in range(len(labels)):\n",
    "            if label_bools[i]:\n",
    "                label_word_counts[labels[i]][token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_frequencies(term, target_label, all_labels, label_word_counts, label_update_totals):\n",
    "    label_freq = label_word_counts[target_label][term]\n",
    "    inv_label_freq = sum([label_word_counts[label][term] for label in all_labels if label != target_label])\n",
    "    \n",
    "    label_notpresent_freq = label_update_totals[target_label] - label_freq\n",
    "    inv_label_notpresent_freq = sum([label_update_totals[label] - label_word_counts[label][term] for label in all_labels if label != target_label])\n",
    "    return label_freq, inv_label_freq, label_notpresent_freq, inv_label_notpresent_freq\n",
    "\n",
    "def get_frequency_odds_ratio(term, target_label, all_labels, label_word_counts, label_update_totals):\n",
    "    label_freq, inv_label_freq, label_notpresent_freq, inv_label_notpresent_freq = get_label_frequencies(term, target_label, all_labels, label_word_counts, label_update_totals)\n",
    "    if label_freq > 0 and inv_label_freq == 0:\n",
    "        # this post appears exclusively in this category\n",
    "        return 1000  # we return an arbitrary high-valued \"OR\", to indicate this is a very good word to select\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        fb_or = (label_freq * inv_label_notpresent_freq) / (label_notpresent_freq * inv_label_freq)\n",
    "    return fb_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_label_token_lists(df, labels, debug=False):\n",
    "    label_word_counts = get_label_word_counts(df, labels)\n",
    "    label_update_totals = {label: np.sum(df[\"is_\" + label]) for label in labels}\n",
    "    if debug:\n",
    "        print(label_update_totals)\n",
    "    \n",
    "    # identify vocab\n",
    "    all_tokens = []\n",
    "    for tokens in df.tokens:\n",
    "        all_tokens += tokens\n",
    "    vocab = set(all_tokens)\n",
    "\n",
    "    # compute odds ratios for each term and label\n",
    "    label_or_map = {label: {} for label in labels}\n",
    "    for token in vocab:\n",
    "        for label in labels:\n",
    "            fb_or = get_frequency_odds_ratio(token, label, labels, label_word_counts, label_update_totals)\n",
    "            label_or_map[label][token] = fb_or\n",
    "            \n",
    "    label_token_lists = {}\n",
    "    for label in labels:\n",
    "        ors = [(token, label_or_map[label][token]) for token in vocab]\n",
    "        or_df = pd.DataFrame(ors, columns=['token', 'fb_or'])\n",
    "        or_df['label_count'] = or_df.token.map(lambda token: label_word_counts[label][token])\n",
    "        pct_of_updates = 0.1  # include only words that occur at least in this percentage of updates with this label\n",
    "        min_updates = int(pct_of_updates * label_update_totals[label])\n",
    "        # apply the filtering, including filtering out infine ORs (indicates discontinuity in use)\n",
    "        or_df = or_df[(or_df.label_count >= min_updates)&(or_df.fb_or != np.inf)]\n",
    "        or_df = or_df.sort_values(by='fb_or', ascending=False)\n",
    "        if debug:\n",
    "            print(label, len(or_df), min_updates)\n",
    "\n",
    "        token_list = or_df.token.head(n=100).tolist()\n",
    "        label_token_lists[label] = token_list\n",
    "        if debug:\n",
    "            print(token_list[:10])\n",
    "        \n",
    "        #printing for debugging\n",
    "        if debug:\n",
    "            display(HTML(or_df.head(10).to_html()))\n",
    "    return label_token_lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_journal(journal_grams, word_list):\n",
    "    return any(word in journal_grams for word in word_list)\n",
    "\n",
    "def eval_model(gram_column, train_journals, test_journals, train_true, test_true, word_list):\n",
    "    \n",
    "    model_eval = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "    \n",
    "    train_predicted = train_journals[gram_column].apply(classify_journal, args=(word_list,))\n",
    "    test_predicted = test_journals[gram_column].apply(classify_journal, args=(word_list,))\n",
    "    \n",
    "    model_eval[0] = sklearn.metrics.recall_score(train_true, train_predicted) #Train recall\n",
    "    model_eval[3] = sklearn.metrics.recall_score(test_true, test_predicted) #Test recall\n",
    "    \n",
    "    model_eval[1] = sklearn.metrics.precision_score(train_true, train_predicted) #Train precision\n",
    "    model_eval[4] = sklearn.metrics.precision_score(test_true, test_predicted) #Test precision\n",
    "    \n",
    "    if train_predicted.any():\n",
    "        model_eval[2] = sklearn.metrics.fbeta_score(train_true, train_predicted, 1) #Train f1\n",
    "    \n",
    "    if test_predicted.any():\n",
    "        model_eval[5] = sklearn.metrics.fbeta_score(test_true, test_predicted, 1) #Test f1\n",
    "    \n",
    "    return model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(journals, labels, cv_iterations=1):\n",
    "    \n",
    "    result_list = []\n",
    "    for i in tqdm(range(cv_iterations), desc='cv iters'):\n",
    "        n_splits = 10\n",
    "        kf = sklearn.model_selection.KFold(n_splits=n_splits, shuffle=True, random_state=i)\n",
    "\n",
    "        #for train_indices, test_indices in tqdm(kf.split(journals), desc='cv', total=n_splits):\n",
    "        for train_indices, test_indices in kf.split(journals):\n",
    "            train_journals = journals.iloc[train_indices]\n",
    "            test_journals = journals.iloc[test_indices]\n",
    "\n",
    "            label_token_lists = compute_label_token_lists(train_journals, labels)\n",
    "\n",
    "            for label in labels:\n",
    "                train_true = train_journals[label + '_score'] > 0.5\n",
    "                test_true = test_journals[label + '_score'] > 0.5\n",
    "\n",
    "                if not any(train_true) or not any(test_true):\n",
    "                    continue  # skip situations where there are zero train or test journals with this label\n",
    "\n",
    "                for k in [10,100]:\n",
    "                    word_list = label_token_lists[label][:k]\n",
    "                    assert len(word_list) == k\n",
    "\n",
    "                    model_result = eval_model('tokens', train_journals, test_journals, train_true, test_true, word_list)\n",
    "                    result_list.append([i, label, k, 'unigram'] + model_result + [word_list[:10]])\n",
    "                                                \n",
    "    column_labels = ['cv_iteration', 'Responsbility/Phase', 'k', 'Token Type', 'Train_R', 'Train_P', 'Train_F1', 'Test_R', 'Test_P', 'Test_F1', 'top_words']\n",
    "    result_df = pd.DataFrame(data=result_list, columns=column_labels)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cv iters: 100%|██████████| 50/50 [1:00:34<00:00, 72.74s/it]\n"
     ]
    }
   ],
   "source": [
    "phase_result_df = cross_validation(annotated_df_phase, phase_labels, cv_iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Responsbility/Phase</th>\n",
       "      <th>k</th>\n",
       "      <th>Token Type</th>\n",
       "      <th>Train_R</th>\n",
       "      <th>Train_P</th>\n",
       "      <th>Train_F1</th>\n",
       "      <th>Test_R</th>\n",
       "      <th>Test_P</th>\n",
       "      <th>Test_F1</th>\n",
       "      <th>top_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretreatment</td>\n",
       "      <td>10</td>\n",
       "      <td>unigram</td>\n",
       "      <td>0.731320</td>\n",
       "      <td>0.129944</td>\n",
       "      <td>0.220676</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.102102</td>\n",
       "      <td>[biopsy, lymph, surgeon, breast, nodes, mri, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretreatment</td>\n",
       "      <td>100</td>\n",
       "      <td>unigram</td>\n",
       "      <td>0.998410</td>\n",
       "      <td>0.074815</td>\n",
       "      <td>0.139200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028908</td>\n",
       "      <td>0.056191</td>\n",
       "      <td>[biopsy, lymph, surgeon, breast, nodes, mri, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>treatment</td>\n",
       "      <td>10</td>\n",
       "      <td>unigram</td>\n",
       "      <td>0.992927</td>\n",
       "      <td>0.860267</td>\n",
       "      <td>0.921849</td>\n",
       "      <td>0.987593</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.920231</td>\n",
       "      <td>[marie, 0|00|00, energy, have, low, chemo, stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>treatment</td>\n",
       "      <td>100</td>\n",
       "      <td>unigram</td>\n",
       "      <td>0.999445</td>\n",
       "      <td>0.858487</td>\n",
       "      <td>0.923619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862955</td>\n",
       "      <td>0.926437</td>\n",
       "      <td>[marie, 0|00|00, energy, have, low, chemo, stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>end_of_life</td>\n",
       "      <td>10</td>\n",
       "      <td>unigram</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.094580</td>\n",
       "      <td>0.167293</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>[hospice, funeral, 00000, beloved, memorial, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Responsbility/Phase    k Token Type   Train_R   Train_P  Train_F1    Test_R  \\\n",
       "0        pretreatment   10    unigram  0.731320  0.129944  0.220676  0.629630   \n",
       "1        pretreatment  100    unigram  0.998410  0.074815  0.139200  1.000000   \n",
       "2           treatment   10    unigram  0.992927  0.860267  0.921849  0.987593   \n",
       "3           treatment  100    unigram  0.999445  0.858487  0.923619  1.000000   \n",
       "4         end_of_life   10    unigram  0.723577  0.094580  0.167293  0.714286   \n",
       "\n",
       "     Test_P   Test_F1                                          top_words  \n",
       "0  0.055556  0.102102  [biopsy, lymph, surgeon, breast, nodes, mri, i...  \n",
       "1  0.028908  0.056191  [biopsy, lymph, surgeon, breast, nodes, mri, i...  \n",
       "2  0.861472  0.920231  [marie, 0|00|00, energy, have, low, chemo, stu...  \n",
       "3  0.862955  0.926437  [marie, 0|00|00, energy, have, low, chemo, stu...  \n",
       "4  0.087719  0.156250  [hospice, funeral, 00000, beloved, memorial, s...  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "phase_result_df_filepath = os.path.join(working_dir, 'oddsratio_phase_results.csv')\n",
    "phase_result_df.to_csv(phase_result_df_filepath)\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_float(val):\n",
    "    if val >= 0 and val < 0.995:\n",
    "        return \"{:.2f}\".format(val)[1:]\n",
    "    elif val >= 0.995:\n",
    "        return \".99\"\n",
    "    else:\n",
    "        raise ValueError(\"Negatives not handled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cured', 10, 'unigram') 450\n",
      ".06 .97 .12 .07 .97 .13\n",
      "{'surgeon', 'free'}\n",
      "\n",
      "('cured', 100, 'unigram') 450\n",
      ".06 .99 .11 .07 .99 .12\n",
      "{'surgeon', 'free'}\n",
      "\n",
      "('end_of_life', 10, 'unigram') 450\n",
      ".10 .73 .18 .11 .72 .18\n",
      "{'funeral', 'memorial', 'service', '00000', 'hospice'}\n",
      "\n",
      "('end_of_life', 100, 'unigram') 450\n",
      ".01 .99 .03 .02 .99 .03\n",
      "{'funeral', 'memorial', 'service', '00000', 'hospice'}\n",
      "\n",
      "('pretreatment', 10, 'unigram') 450\n",
      ".12 .72 .21 .12 .71 .20\n",
      "{'nodes', 'breast', 'biopsy', 'lymph', 'surgery', 'surgeon'}\n",
      "\n",
      "('pretreatment', 100, 'unigram') 450\n",
      ".07 .99 .13 .08 .99 .14\n",
      "{'nodes', 'breast', 'biopsy', 'lymph', 'surgery', 'surgeon'}\n",
      "\n",
      "('treatment', 10, 'unigram') 500\n",
      ".88 .92 .89 .88 .90 .88\n",
      "{'energy', 'chemo', 'yesterday', 'effects'}\n",
      "\n",
      "('treatment', 100, 'unigram') 500\n",
      ".86 .99 .92 .86 .99 .92\n",
      "{'energy', 'chemo', 'yesterday', 'effects'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, group in phase_result_df.groupby(by=['Responsbility/Phase', 'k', 'Token Type']):\n",
    "    print(key, len(group))\n",
    "    train_r = format_float(np.mean(group.Train_R))\n",
    "    train_p = format_float(np.mean(group.Train_P))\n",
    "    train_f1 = format_float(np.mean(group.Train_F1))\n",
    "    test_r = format_float(np.mean(group.Test_R))\n",
    "    test_p = format_float(np.mean(group.Test_P))\n",
    "    test_f1 = format_float(np.mean(group.Test_F1))\n",
    "    print(train_p, train_r, train_f1, test_p, test_r, test_f1)\n",
    "    \n",
    "    top_words = None\n",
    "    for words in group.top_words:\n",
    "        if top_words is None:\n",
    "            top_words = set(words)\n",
    "        else:\n",
    "            top_words = set(words) & top_words\n",
    "    print(top_words)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cv iters: 100%|██████████| 50/50 [26:22<00:00, 31.58s/it]\n"
     ]
    }
   ],
   "source": [
    "resp_result_df = cross_validation(annotated_df_resp, resp_subset, cv_iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "resp_result_df_filepath = os.path.join(working_dir, 'oddsratio_resp_results.csv')\n",
    "resp_result_df.to_csv(resp_result_df_filepath)\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('behavior_changes', 10, 'unigram')\n",
      ".14 .69 .23 .08 .42 .13\n",
      "{'exercise'}\n",
      "exercise, caring, walk, miles, minute, race, walking, attitude, recently, run, avoid, spring, healthy, shape, weight, fighting\n",
      "\n",
      "('behavior_changes', 100, 'unigram')\n",
      ".04 .99 .08 .04 .99 .08\n",
      "{'exercise'}\n",
      "\n",
      "('compliance', 10, 'unigram')\n",
      ".77 .99 .87 .77 .99 .87\n",
      "{'.', 'monday'}\n",
      "wait, results, finally, round, left, monday, then, appointment, pain, newline, i, ., test, |\n",
      "\n",
      "('compliance', 100, 'unigram')\n",
      ".77 .99 .87 .77 .99 .87\n",
      "{'.', 'monday'}\n",
      "\n",
      "('coordinating_support', 10, 'unigram')\n",
      ".24 .88 .37 .23 .86 .36\n",
      "{'please', 'keep', 'pray', 'praying'}\n",
      "please, http, ask, spend, send, praying, mine, prayer, continue, pray, |, pooh, keep\n",
      "\n",
      "('coordinating_support', 100, 'unigram')\n",
      ".15 .99 .26 .15 .99 .26\n",
      "{'please', 'keep', 'pray', 'praying'}\n",
      "\n",
      "('financial_management', 10, 'unigram')\n",
      ".22 .87 .35 .20 .77 .30\n",
      "{'$', 'insurance'}\n",
      "pay, disability, charlotte, insurance, runs, opinion, be, provide, $, 0|000, bills\n",
      "\n",
      "('financial_management', 100, 'unigram')\n",
      ".03 .98 .06 .03 .98 .07\n",
      "{'$', 'insurance'}\n",
      "\n",
      "('giving_back', 10, 'unigram')\n",
      ".16 .65 .25 .12 .50 .19\n",
      "set()\n",
      "sharing, race, join, team, battle, reach, service, raise, women, money, research, scared, relay\n",
      "\n",
      "('giving_back', 100, 'unigram')\n",
      ".04 .98 .08 .04 .98 .08\n",
      "set()\n",
      "\n",
      "('sharing_medical_info', 10, 'unigram')\n",
      ".86 .98 .92 .86 .98 .92\n",
      "{'pain'}\n",
      "weekend, night, grateful, pain, home, newline, i, soon, ., hopefully, happy, news\n",
      "\n",
      "('sharing_medical_info', 100, 'unigram')\n",
      ".86 .99 .93 .86 .99 .93\n",
      "{'pain'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, group in resp_result_df.groupby(by=['Responsbility/Phase', 'k', 'Token Type']):\n",
    "    print(key)\n",
    "    train_r = format_float(np.mean(group.Train_R))\n",
    "    train_p = format_float(np.mean(group.Train_P))\n",
    "    train_f1 = format_float(np.mean(group.Train_F1))\n",
    "    test_r = format_float(np.mean(group.Test_R))\n",
    "    test_p = format_float(np.mean(group.Test_P))\n",
    "    test_f1 = format_float(np.mean(group.Test_F1))\n",
    "    print(train_p, train_r, train_f1, test_p, test_r, test_f1)\n",
    "    \n",
    "    top_words = None\n",
    "    for words in group.top_words:\n",
    "        if top_words is None:\n",
    "            top_words = set(words)\n",
    "        else:\n",
    "            top_words = set(words) & top_words\n",
    "    print(top_words)\n",
    "    \n",
    "    # words that appear in at least X% of CV folds\n",
    "    if key[1] == 10:\n",
    "        from collections import defaultdict\n",
    "        word_counts = defaultdict(int)\n",
    "        for cv, g in group.groupby(by='cv_iteration'):\n",
    "            words = []\n",
    "            for word_list in g.top_words:\n",
    "                words.extend(word_list)\n",
    "            for word in set(words):\n",
    "                word_counts[word] += 1\n",
    "        top_words = []\n",
    "        for word in word_counts:\n",
    "            word_count = word_counts[word]\n",
    "            if word_count == 50:\n",
    "                top_words.append(word)\n",
    "        print(\", \".join(top_words))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS & .24 & .88 & .37 & .23 & .86 & .36 & .26 & .26 \\\\\n",
      "SM & .86 & .98 & .92 & .86 & .98 & .92 & .93 & .93 \\\\\n",
      "CP & .77 & .99 & .87 & .77 & .99 & .87 & .87 & .87 \\\\\n",
      "FM & .22 & .87 & .35 & .20 & .77 & .30 & .06 & .07 \\\\\n",
      "GB & .16 & .65 & .25 & .12 & .50 & .19 & .08 & .08 \\\\\n",
      "BC & .14 & .69 & .23 & .08 & .42 & .13 & .08 & .08 \\\\\n"
     ]
    }
   ],
   "source": [
    "for resp_label in resp_subset:\n",
    "    resp_code = responsibility_label_to_code_map[resp_label]\n",
    "    \n",
    "    subset_df = resp_result_df[resp_result_df['Responsbility/Phase'] == resp_label]\n",
    "    k10_df = subset_df[subset_df.k == 10]\n",
    "    k100_df = subset_df[subset_df.k == 100]\n",
    "    \n",
    "    k10_train_p = format_float(np.mean(k10_df.Train_P))\n",
    "    k10_train_r = format_float(np.mean(k10_df.Train_R))\n",
    "    k10_train_f1 = format_float(np.mean(k10_df.Train_F1))\n",
    "    k10_test_p = format_float(np.mean(k10_df.Test_P))\n",
    "    k10_test_r = format_float(np.mean(k10_df.Test_R))\n",
    "    k10_test_f1 = format_float(np.mean(k10_df.Test_F1))\n",
    "    \n",
    "    k100_train_p = format_float(np.mean(k100_df.Train_P))\n",
    "    k100_train_r = format_float(np.mean(k100_df.Train_R))\n",
    "    k100_train_f1 = format_float(np.mean(k100_df.Train_F1))\n",
    "    k100_test_p = format_float(np.mean(k100_df.Test_P))\n",
    "    k100_test_r = format_float(np.mean(k100_df.Test_R))\n",
    "    k100_test_f1 = format_float(np.mean(k100_df.Test_F1))\n",
    "\n",
    "    print(f\"{resp_code} & {k10_train_p} & {k10_train_r} & {k10_train_f1} & {k10_test_p} & {k10_test_r} & {k10_test_f1} & {k100_train_f1} & {k100_test_f1} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT & .12 & .72 & .21 & .12 & .71 & .20 & .13 & .14 \\\\\n",
      "T & .88 & .92 & .89 & .88 & .90 & .88 & .92 & .92 \\\\\n",
      "EOL & .10 & .73 & .18 & .11 & .72 & .18 & .03 & .03 \\\\\n",
      "NED & .06 & .97 & .12 & .07 & .97 & .13 & .11 & .12 \\\\\n"
     ]
    }
   ],
   "source": [
    "for phase_code, phase_label in zip([\"PT\", \"T\", \"EOL\", \"NED\"], phase_labels):\n",
    "    subset_df = phase_result_df[phase_result_df['Responsbility/Phase'] == phase_label]\n",
    "    k10_df = subset_df[subset_df.k == 10]\n",
    "    k100_df = subset_df[subset_df.k == 100]\n",
    "    \n",
    "    k10_train_p = format_float(np.mean(k10_df.Train_P))\n",
    "    k10_train_r = format_float(np.mean(k10_df.Train_R))\n",
    "    k10_train_f1 = format_float(np.mean(k10_df.Train_F1))\n",
    "    k10_test_p = format_float(np.mean(k10_df.Test_P))\n",
    "    k10_test_r = format_float(np.mean(k10_df.Test_R))\n",
    "    k10_test_f1 = format_float(np.mean(k10_df.Test_F1))\n",
    "    \n",
    "    k100_train_p = format_float(np.mean(k100_df.Train_P))\n",
    "    k100_train_r = format_float(np.mean(k100_df.Train_R))\n",
    "    k100_train_f1 = format_float(np.mean(k100_df.Train_F1))\n",
    "    k100_test_p = format_float(np.mean(k100_df.Test_P))\n",
    "    k100_test_r = format_float(np.mean(k100_df.Test_R))\n",
    "    k100_test_f1 = format_float(np.mean(k100_df.Test_F1))\n",
    "\n",
    "    print(f\"{phase_code} & {k10_train_p} & {k10_train_r} & {k10_train_f1} & {k10_test_p} & {k10_test_r} & {k10_test_f1} & {k100_train_f1} & {k100_test_f1} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original experiments proping the odds-ratio approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9336/9336 [00:03<00:00, 3098.17it/s]\n",
      "100%|██████████| 9336/9336 [00:00<00:00, 306496.73it/s]\n",
      "  0%|          | 0/43601 [00:00<?, ?it/s]/home/srivbane/shared/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pretreatment': 656, 'treatment': 8017, 'end_of_life': 130, 'cured': 560}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 13688/43601 [00:00<00:00, 45406.97it/s]/home/srivbane/shared/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  from ipykernel import kernelapp as app\n",
      "100%|██████████| 43601/43601 [00:00<00:00, 45656.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretreatment 235 65\n",
      "['biopsy', 'lymph', 'surgeon', 'breast', 'nodes', 'mri', 'test', 'surgery', 'information', 'doctors']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>fb_or</th>\n",
       "      <th>label_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>biopsy</td>\n",
       "      <td>6.466923</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>lymph</td>\n",
       "      <td>4.849914</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6010</th>\n",
       "      <td>surgeon</td>\n",
       "      <td>4.189981</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9072</th>\n",
       "      <td>breast</td>\n",
       "      <td>3.899716</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14725</th>\n",
       "      <td>nodes</td>\n",
       "      <td>3.490746</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20675</th>\n",
       "      <td>mri</td>\n",
       "      <td>3.005103</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41738</th>\n",
       "      <td>test</td>\n",
       "      <td>2.771163</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7662</th>\n",
       "      <td>surgery</td>\n",
       "      <td>2.701096</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37794</th>\n",
       "      <td>information</td>\n",
       "      <td>2.581310</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14293</th>\n",
       "      <td>doctors</td>\n",
       "      <td>2.430652</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treatment 263 801\n",
      "['energy', 'have', 'low', 'chemo', 'effects', 'yesterday', 'blood', 'tired', 'stuff', '|']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>fb_or</th>\n",
       "      <th>label_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17684</th>\n",
       "      <td>energy</td>\n",
       "      <td>4.252816</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290</th>\n",
       "      <td>have</td>\n",
       "      <td>3.576392</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5745</th>\n",
       "      <td>low</td>\n",
       "      <td>3.002576</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36707</th>\n",
       "      <td>chemo</td>\n",
       "      <td>2.419820</td>\n",
       "      <td>3895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31293</th>\n",
       "      <td>effects</td>\n",
       "      <td>2.245111</td>\n",
       "      <td>1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>yesterday</td>\n",
       "      <td>2.202190</td>\n",
       "      <td>2121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43469</th>\n",
       "      <td>blood</td>\n",
       "      <td>1.950758</td>\n",
       "      <td>1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41232</th>\n",
       "      <td>tired</td>\n",
       "      <td>1.931560</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16161</th>\n",
       "      <td>stuff</td>\n",
       "      <td>1.893442</td>\n",
       "      <td>1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14919</th>\n",
       "      <td>|</td>\n",
       "      <td>1.875749</td>\n",
       "      <td>7911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end_of_life 256 13\n",
      "['hospice', 'funeral', '00000', 'memorial', 'service', 'passed', 'surrounded', 'held', 'services', 'jesus']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>fb_or</th>\n",
       "      <th>label_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26076</th>\n",
       "      <td>hospice</td>\n",
       "      <td>112.405172</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>funeral</td>\n",
       "      <td>31.142901</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7965</th>\n",
       "      <td>00000</td>\n",
       "      <td>25.493062</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>memorial</td>\n",
       "      <td>22.219512</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4591</th>\n",
       "      <td>service</td>\n",
       "      <td>20.540350</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19362</th>\n",
       "      <td>passed</td>\n",
       "      <td>13.687908</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8285</th>\n",
       "      <td>surrounded</td>\n",
       "      <td>12.819074</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36246</th>\n",
       "      <td>held</td>\n",
       "      <td>11.137498</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>services</td>\n",
       "      <td>9.848975</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15685</th>\n",
       "      <td>jesus</td>\n",
       "      <td>9.048611</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cured 281 56\n",
      "['i', 'surgeon', 'sheri', 'free', 'breast', 'recovery', 'months', 'healing', 'year', 'removed']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>fb_or</th>\n",
       "      <th>label_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32955</th>\n",
       "      <td>i</td>\n",
       "      <td>3.268917</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6010</th>\n",
       "      <td>surgeon</td>\n",
       "      <td>3.128352</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41559</th>\n",
       "      <td>sheri</td>\n",
       "      <td>3.004126</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39455</th>\n",
       "      <td>free</td>\n",
       "      <td>2.935998</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9072</th>\n",
       "      <td>breast</td>\n",
       "      <td>2.728781</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41113</th>\n",
       "      <td>recovery</td>\n",
       "      <td>2.651746</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6408</th>\n",
       "      <td>months</td>\n",
       "      <td>2.615370</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14500</th>\n",
       "      <td>healing</td>\n",
       "      <td>2.489125</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326</th>\n",
       "      <td>year</td>\n",
       "      <td>2.464099</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>removed</td>\n",
       "      <td>2.398451</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_token_lists = compute_label_token_lists(annotated_df_phase, phase_labels, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pretreatment': defaultdict(int, {}),\n",
       " 'treatment': defaultdict(int, {}),\n",
       " 'end_of_life': defaultdict(int, {}),\n",
       " 'cured': defaultdict(int, {})}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_word_counts = {phase_label: defaultdict(int) for phase_label in phase_labels}\n",
    "phase_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_pretreatment', 'is_treatment', 'is_end_of_life', 'is_cured']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_label_cols = [\"is_\" + phase_label for phase_label in phase_labels]\n",
    "\n",
    "def update_counts(entry):\n",
    "    phase_label_bools = [entry[phase_label_col] for phase_label_col in phase_label_cols]\n",
    "    tokens = entry.tokens\n",
    "    for token in set(tokens):\n",
    "        for i in range(4):\n",
    "            if phase_label_bools[i]:\n",
    "                phase_word_counts[phase_labels[i]][token] += 1\n",
    "                \n",
    "phase_label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9336/9336 [00:03<00:00, 2976.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for _, row in tqdm(annotated_df_phase.iterrows(), total=len(annotated_df_phase)):\n",
    "    update_counts(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_word_counts['treatment']['cancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pretreatment': 656, 'treatment': 8017, 'end_of_life': 130, 'cured': 560}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_update_totals = {phase_label: np.sum(annotated_df_phase[\"is_\" + phase_label]) for phase_label in phase_labels}\n",
    "phase_update_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9336/9336 [00:00<00:00, 240549.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43601"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens = []\n",
    "for tokens in tqdm(annotated_df_phase.tokens):\n",
    "    all_tokens += tokens\n",
    "phase_vocab = set(all_tokens)\n",
    "len(phase_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phase_frequencies(term, phase):\n",
    "    phase_freq = phase_word_counts[phase][term]\n",
    "    inv_phase_freq = sum([phase_word_counts[phase_label][term] for phase_label in phase_labels if phase_label != phase])\n",
    "    \n",
    "    phase_notpresent_freq = phase_update_totals[phase] - phase_freq\n",
    "    inv_phase_notpresent_freq = sum([phase_update_totals[phase_label] - phase_word_counts[phase_label][term] for phase_label in phase_labels if phase_label != phase])\n",
    "    return phase_freq, inv_phase_freq, phase_notpresent_freq, inv_phase_notpresent_freq\n",
    "\n",
    "def get_frequency_odds_ratio(term, phase):\n",
    "    phase_freq, inv_phase_freq, phase_notpresent_freq, inv_phase_notpresent_freq = get_phase_frequencies(term, phase)\n",
    "    try:\n",
    "        fb_or = (phase_freq * inv_phase_notpresent_freq) / (phase_notpresent_freq * inv_phase_freq)\n",
    "    except:\n",
    "        fb_or = -10000\n",
    "    return fb_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43601 [00:00<?, ?it/s]/home/srivbane/shared/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  if sys.path[0] == '':\n",
      "/home/srivbane/shared/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if sys.path[0] == '':\n",
      "100%|██████████| 43601/43601 [00:01<00:00, 40406.79it/s]\n"
     ]
    }
   ],
   "source": [
    "phase_or_map = {phase_label: {} for phase_label in phase_labels}\n",
    "for token in tqdm(phase_vocab):\n",
    "    for phase in phase_labels:\n",
    "        fb_or = get_frequency_odds_ratio(token, phase)\n",
    "        phase_or_map[phase][token] = fb_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretreatment\n",
      "65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>fb_or</th>\n",
       "      <th>phase_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38013</th>\n",
       "      <td>biopsy</td>\n",
       "      <td>6.466923</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20310</th>\n",
       "      <td>lymph</td>\n",
       "      <td>4.849914</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8004</th>\n",
       "      <td>surgeon</td>\n",
       "      <td>4.189981</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>breast</td>\n",
       "      <td>3.899716</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>nodes</td>\n",
       "      <td>3.490746</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29260</th>\n",
       "      <td>mri</td>\n",
       "      <td>3.005103</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36260</th>\n",
       "      <td>test</td>\n",
       "      <td>2.771163</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33191</th>\n",
       "      <td>surgery</td>\n",
       "      <td>2.701096</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19917</th>\n",
       "      <td>information</td>\n",
       "      <td>2.581310</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35109</th>\n",
       "      <td>doctors</td>\n",
       "      <td>2.430652</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25853</th>\n",
       "      <td>received</td>\n",
       "      <td>2.423199</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8088</th>\n",
       "      <td>tests</td>\n",
       "      <td>2.229885</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23264</th>\n",
       "      <td>chemotherapy</td>\n",
       "      <td>2.212366</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31371</th>\n",
       "      <td>begin</td>\n",
       "      <td>1.893220</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>waiting</td>\n",
       "      <td>1.816842</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "treatment\n",
      "801\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>fb_or</th>\n",
       "      <th>phase_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5684</th>\n",
       "      <td>energy</td>\n",
       "      <td>4.252816</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24019</th>\n",
       "      <td>have</td>\n",
       "      <td>3.576392</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6366</th>\n",
       "      <td>low</td>\n",
       "      <td>3.002576</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>chemo</td>\n",
       "      <td>2.419820</td>\n",
       "      <td>3895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41150</th>\n",
       "      <td>effects</td>\n",
       "      <td>2.245111</td>\n",
       "      <td>1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12914</th>\n",
       "      <td>yesterday</td>\n",
       "      <td>2.202190</td>\n",
       "      <td>2121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27090</th>\n",
       "      <td>blood</td>\n",
       "      <td>1.950758</td>\n",
       "      <td>1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11119</th>\n",
       "      <td>tired</td>\n",
       "      <td>1.931560</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9247</th>\n",
       "      <td>stuff</td>\n",
       "      <td>1.893442</td>\n",
       "      <td>1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30771</th>\n",
       "      <td>|</td>\n",
       "      <td>1.875749</td>\n",
       "      <td>7911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34049</th>\n",
       "      <td>etc</td>\n",
       "      <td>1.863792</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33439</th>\n",
       "      <td>day</td>\n",
       "      <td>1.846083</td>\n",
       "      <td>4703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33441</th>\n",
       "      <td>far</td>\n",
       "      <td>1.717776</td>\n",
       "      <td>1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24161</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>1.711766</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34942</th>\n",
       "      <td>seems</td>\n",
       "      <td>1.702156</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "end_of_life\n",
      "13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>fb_or</th>\n",
       "      <th>phase_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33381</th>\n",
       "      <td>hospice</td>\n",
       "      <td>112.405172</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>funeral</td>\n",
       "      <td>31.142901</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41851</th>\n",
       "      <td>00000</td>\n",
       "      <td>25.493062</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17711</th>\n",
       "      <td>memorial</td>\n",
       "      <td>22.219512</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8722</th>\n",
       "      <td>service</td>\n",
       "      <td>20.540350</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20172</th>\n",
       "      <td>passed</td>\n",
       "      <td>13.687908</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20176</th>\n",
       "      <td>surrounded</td>\n",
       "      <td>12.819074</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17524</th>\n",
       "      <td>held</td>\n",
       "      <td>11.137498</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>services</td>\n",
       "      <td>9.848975</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18783</th>\n",
       "      <td>jesus</td>\n",
       "      <td>9.048611</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41425</th>\n",
       "      <td>mother</td>\n",
       "      <td>7.421603</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17753</th>\n",
       "      <td>her</td>\n",
       "      <td>6.174946</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34830</th>\n",
       "      <td>welcome</td>\n",
       "      <td>5.838281</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>battle</td>\n",
       "      <td>5.697521</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28404</th>\n",
       "      <td>church</td>\n",
       "      <td>5.282730</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cured\n",
      "56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>fb_or</th>\n",
       "      <th>phase_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32516</th>\n",
       "      <td>i</td>\n",
       "      <td>3.268917</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13083</th>\n",
       "      <td>surgeon</td>\n",
       "      <td>3.128352</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>sheri</td>\n",
       "      <td>3.004126</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32324</th>\n",
       "      <td>free</td>\n",
       "      <td>2.935998</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18831</th>\n",
       "      <td>breast</td>\n",
       "      <td>2.728781</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>recovery</td>\n",
       "      <td>2.651746</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42671</th>\n",
       "      <td>months</td>\n",
       "      <td>2.615370</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22859</th>\n",
       "      <td>healing</td>\n",
       "      <td>2.489125</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20126</th>\n",
       "      <td>year</td>\n",
       "      <td>2.464099</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17158</th>\n",
       "      <td>removed</td>\n",
       "      <td>2.398451</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34570</th>\n",
       "      <td>surgery</td>\n",
       "      <td>2.219256</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621</th>\n",
       "      <td>posted</td>\n",
       "      <td>2.086741</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30994</th>\n",
       "      <td>happy</td>\n",
       "      <td>2.040968</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20044</th>\n",
       "      <td>journey</td>\n",
       "      <td>2.012015</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19141</th>\n",
       "      <td>comments</td>\n",
       "      <td>1.939671</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_token_lists = {}\n",
    "for phase_label in phase_labels:\n",
    "    print(phase_label)\n",
    "    ors = [(token, phase_or_map[phase_label][token]) for token in phase_vocab]\n",
    "    ors.sort(reverse=True, key=lambda tup: tup[1])\n",
    "    phase_ors = pd.DataFrame(ors, columns=['token', 'fb_or'])\n",
    "    phase_ors['phase_count'] = phase_ors.token.map(lambda token: phase_word_counts[phase_label][token])\n",
    "    n = 15\n",
    "    pct_of_updates = int(0.1 * phase_update_totals[phase_label])\n",
    "    print(pct_of_updates)\n",
    "    phase_ors_subset = phase_ors[(phase_ors.phase_count >= pct_of_updates)&(phase_ors.fb_or!=np.inf)]\n",
    "    phase_ors_subset = phase_ors_subset.sort_values(by='fb_or', ascending=False)\n",
    "    \n",
    "    token_list = phase_ors_subset.token.head(n=100).tolist()\n",
    "    label_token_lists[phase_label] = token_list\n",
    "    \n",
    "    display(HTML(phase_ors_subset.head(n).to_html()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
